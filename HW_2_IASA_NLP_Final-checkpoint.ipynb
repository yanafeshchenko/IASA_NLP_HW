{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1fd4c4",
   "metadata": {},
   "source": [
    "# <center>Homework 2</center><center>CommonLit - Evaluate Students' Summaries</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d1c3e",
   "metadata": {},
   "source": [
    "## Task formalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92127fc",
   "metadata": {},
   "source": [
    "The <b>purpose</b> is to build a ML model that will predict scores of the summaries written by students.<br>\n",
    "In the dataset we have <u>2 target variables:</u> <b>wording</b> and <b>content</b> scoring.<br><br>\n",
    "The next step is analyzing with other columns in the given datasets. <br>\n",
    "<u><b>Student_ID</b></u>: the ID of a student. <br>\n",
    "<u><b>Prompt_ID</b></u>: the ID of a prompt. <br>\n",
    "<u><b>Text</b></u>: the text of a student's summary. <br>\n",
    "<u><b>Content</b></u>: content scoring. <br>\n",
    "<u><b>Wording</b></u>: word scoring. <br>\n",
    "<u><b>Prompt_Question</b></u>: the specific question the students are asked to respond to. <br>\n",
    "<u><b>Prompt_Title</b></u>: a short-hand title for the prompt. <br>\n",
    "<u><b>Prompt_Text</b></u>: the full prompt text. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf26825",
   "metadata": {},
   "source": [
    "<b>Note:</b> in this notebook I will use some analysis that I made in HW 1 but with several changes. In case if you need the link for my previous homework, I will leave it right there https://colab.research.google.com/drive/1gmPUytB9JJBlXF2mw8xaJCZ2kjloIwky ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14b2af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27fcacf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize     \n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c986bd",
   "metadata": {},
   "source": [
    "<font size=\"4\">First step - loading the data and getting familiar with it.<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45b4a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train = pd.read_csv('D:\\iasa_nlp/summaries_train.csv')\n",
    "summaries_test = pd.read_csv('D:\\iasa_nlp/summaries_test.csv')\n",
    "prompts_train = pd.read_csv('D:\\iasa_nlp/prompts_train.csv')\n",
    "prompts_test = pd.read_csv('D:\\iasa_nlp/prompts_test.csv')\n",
    "sample_submission = pd.read_csv('D:\\iasa_nlp/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1f8300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train dataset of summaries: (7165, 5)\n",
      "The size of test dataset of summaries: (4, 3)\n",
      "The size of train dataset of prompts: (4, 4)\n",
      "The size of test dataset of prompts: (2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of train dataset of summaries:\", summaries_train.shape)\n",
    "print(\"The size of test dataset of summaries:\", summaries_test.shape)\n",
    "print(\"The size of train dataset of prompts:\", prompts_train.shape)\n",
    "print(\"The size of test dataset of prompts:\", prompts_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3287eac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ffc34d056498</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The lowest classes are slaves and farmers slav...</td>\n",
       "      <td>-0.308448</td>\n",
       "      <td>0.048171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ffd1576d2e1b</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>they sorta made people start workin...</td>\n",
       "      <td>-1.408180</td>\n",
       "      <td>-0.493603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ffe4a98093b2</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>An ideal tragety has three elements that make ...</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        student_id prompt_id  \\\n",
       "0     000e8c3c7ddb    814d6b   \n",
       "1     0020ae56ffbf    ebad26   \n",
       "2     004e978e639e    3b9047   \n",
       "3     005ab0199905    3b9047   \n",
       "4     0070c9e7af47    814d6b   \n",
       "...            ...       ...   \n",
       "7160  ff7c7e70df07    ebad26   \n",
       "7161  ffc34d056498    3b9047   \n",
       "7162  ffd1576d2e1b    3b9047   \n",
       "7163  ffe4a98093b2    39c16e   \n",
       "7164  fffbccfd8a08    ebad26   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     The third wave was an experimentto see how peo...  0.205683  0.380538  \n",
       "1     They would rub it up with soda to make the sme... -0.548304  0.506755  \n",
       "2     In Egypt, there were many occupations and soci...  3.128928  4.231226  \n",
       "3     The highest class was Pharaohs these people we... -0.210614 -0.471415  \n",
       "4     The Third Wave developed  rapidly because the ...  3.272894  3.219757  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7161  The lowest classes are slaves and farmers slav... -0.308448  0.048171  \n",
       "7162             they sorta made people start workin... -1.408180 -0.493603  \n",
       "7163  An ideal tragety has three elements that make ... -0.393310  0.627128  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7155eb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3b9047</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>814d6b</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prompt_id                                    prompt_question  \\\n",
       "0    39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1    3b9047  In complete sentences, summarize the structure...   \n",
       "2    814d6b  Summarize how the Third Wave developed over su...   \n",
       "3    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                prompt_title  \\\n",
       "0                 On Tragedy   \n",
       "1  Egyptian Social Structure   \n",
       "2             The Third Wave   \n",
       "3    Excerpt from The Jungle   \n",
       "\n",
       "                                         prompt_text  \n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n",
       "1  Egyptian society was structured like a pyramid...  \n",
       "2  Background \\r\\nThe Third Wave experiment took ...  \n",
       "3  With one member trimming beef in a cannery, an...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d9b8b",
   "metadata": {},
   "source": [
    "It's more comfortable to join these datasets into the one, so let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22e8a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = prompts_train.merge(summaries_train, on=\"prompt_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5748fd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00cd5736026a</td>\n",
       "      <td>One element of an Ideal tragedy is having a co...</td>\n",
       "      <td>0.088882</td>\n",
       "      <td>-0.594710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00d98b8ff756</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>-0.687288</td>\n",
       "      <td>-0.460886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff37545b2805</td>\n",
       "      <td>In paragraph two, they would use pickle meat a...</td>\n",
       "      <td>1.520355</td>\n",
       "      <td>-0.292990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff4ed38ef099</td>\n",
       "      <td>in the first paragraph  it says \"either can it...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff53b94f7ce0</td>\n",
       "      <td>They would have piles of filthy meat on the fl...</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>-1.053294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                    prompt_question  \\\n",
       "0       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "2       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "3       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "4       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "...        ...                                                ...   \n",
       "7160    ebad26  Summarize the various ways the factory would u...   \n",
       "7161    ebad26  Summarize the various ways the factory would u...   \n",
       "7162    ebad26  Summarize the various ways the factory would u...   \n",
       "7163    ebad26  Summarize the various ways the factory would u...   \n",
       "7164    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "0                  On Tragedy   \n",
       "1                  On Tragedy   \n",
       "2                  On Tragedy   \n",
       "3                  On Tragedy   \n",
       "4                  On Tragedy   \n",
       "...                       ...   \n",
       "7160  Excerpt from The Jungle   \n",
       "7161  Excerpt from The Jungle   \n",
       "7162  Excerpt from The Jungle   \n",
       "7163  Excerpt from The Jungle   \n",
       "7164  Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text    student_id  \\\n",
       "0     Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1     Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "2     Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n",
       "3     Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n",
       "4     Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n",
       "...                                                 ...           ...   \n",
       "7160  With one member trimming beef in a cannery, an...  ff37545b2805   \n",
       "7161  With one member trimming beef in a cannery, an...  ff4ed38ef099   \n",
       "7162  With one member trimming beef in a cannery, an...  ff53b94f7ce0   \n",
       "7163  With one member trimming beef in a cannery, an...  ff7c7e70df07   \n",
       "7164  With one member trimming beef in a cannery, an...  fffbccfd8a08   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1     The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2     Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n",
       "3     One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n",
       "4     The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  In paragraph two, they would use pickle meat a...  1.520355 -0.292990  \n",
       "7161  in the first paragraph  it says \"either can it... -1.204574 -1.169784  \n",
       "7162  They would have piles of filthy meat on the fl...  0.328739 -1.053294  \n",
       "7163  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82f54a2",
   "metadata": {},
   "source": [
    "## Step two -  EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7992a",
   "metadata": {},
   "source": [
    "In this notebook I didn't include this step as I think I should more emphasize on manipulations with text data. In case you need to look at EDA, you can use my Homework no.1. The link is on the top of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b464d",
   "metadata": {},
   "source": [
    "## Step three - Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce030b",
   "metadata": {},
   "source": [
    "Let's look at our data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244b6e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>0094589c7a22</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00cd5736026a</td>\n",
       "      <td>One element of an Ideal tragedy is having a co...</td>\n",
       "      <td>0.088882</td>\n",
       "      <td>-0.594710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39c16e</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>00d98b8ff756</td>\n",
       "      <td>The 3 ideal of tragedy is how complex you need...</td>\n",
       "      <td>-0.687288</td>\n",
       "      <td>-0.460886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff37545b2805</td>\n",
       "      <td>In paragraph two, they would use pickle meat a...</td>\n",
       "      <td>1.520355</td>\n",
       "      <td>-0.292990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff4ed38ef099</td>\n",
       "      <td>in the first paragraph  it says \"either can it...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff53b94f7ce0</td>\n",
       "      <td>They would have piles of filthy meat on the fl...</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>-1.053294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7165 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                    prompt_question  \\\n",
       "0       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "1       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "2       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "3       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "4       39c16e  Summarize at least 3 elements of an ideal trag...   \n",
       "...        ...                                                ...   \n",
       "7160    ebad26  Summarize the various ways the factory would u...   \n",
       "7161    ebad26  Summarize the various ways the factory would u...   \n",
       "7162    ebad26  Summarize the various ways the factory would u...   \n",
       "7163    ebad26  Summarize the various ways the factory would u...   \n",
       "7164    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "0                  On Tragedy   \n",
       "1                  On Tragedy   \n",
       "2                  On Tragedy   \n",
       "3                  On Tragedy   \n",
       "4                  On Tragedy   \n",
       "...                       ...   \n",
       "7160  Excerpt from The Jungle   \n",
       "7161  Excerpt from The Jungle   \n",
       "7162  Excerpt from The Jungle   \n",
       "7163  Excerpt from The Jungle   \n",
       "7164  Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text    student_id  \\\n",
       "0     Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f   \n",
       "1     Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f   \n",
       "2     Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22   \n",
       "3     Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a   \n",
       "4     Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756   \n",
       "...                                                 ...           ...   \n",
       "7160  With one member trimming beef in a cannery, an...  ff37545b2805   \n",
       "7161  With one member trimming beef in a cannery, an...  ff4ed38ef099   \n",
       "7162  With one member trimming beef in a cannery, an...  ff53b94f7ce0   \n",
       "7163  With one member trimming beef in a cannery, an...  ff7c7e70df07   \n",
       "7164  With one member trimming beef in a cannery, an...  fffbccfd8a08   \n",
       "\n",
       "                                                   text   content   wording  \n",
       "0     1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1     The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2     Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  \n",
       "3     One element of an Ideal tragedy is having a co...  0.088882 -0.594710  \n",
       "4     The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886  \n",
       "...                                                 ...       ...       ...  \n",
       "7160  In paragraph two, they would use pickle meat a...  1.520355 -0.292990  \n",
       "7161  in the first paragraph  it says \"either can it... -1.204574 -1.169784  \n",
       "7162  They would have piles of filthy meat on the fl...  0.328739 -1.053294  \n",
       "7163  They used all sorts of chemical concoctions to...  0.205683  0.380538  \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742  \n",
       "\n",
       "[7165 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c243b7",
   "metadata": {},
   "source": [
    "We should put our focus on the <b>text</b> column which contains the summary text. I will use several text preprocessing techniques with this parameter. But firstly, let's remind of them:\n",
    "- lowercasing;\n",
    "- removing stopwords;\n",
    "- removing punctuation;\n",
    "- tokenization;\n",
    "- stemming & lemmatization. <br>\n",
    "\n",
    "Depending on the business task, we should think which methods are necessary to use and which ones will be meaningless or do some harm for our data.<br>\n",
    "Content score mostly estimates the idea of the summary; whether a student used key words to describe things etc. Wording scoring estimates vocabulary, spelling and grammar.\n",
    "In my opinion, we should use different manipulations with text based on the target variable we choose. To me, it's a bad idea to remove punctuation or make stemming/lemmatization if we want to predict wording score, for instance. So, I'll create 2 different columns with cleaned text and use them separately for my future models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc37b9",
   "metadata": {},
   "source": [
    "Text preprocessing for CONTENT variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a7517c",
   "metadata": {},
   "source": [
    "To start with, I'll create the column <b>'light_text'</b>. Here I will clean the given text from unimportant punctuation & do sentence tokenization. As a result, there won't be a lot of changes in the text data. \n",
    "This column is considered to be the key for target <b>[wording]</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215f7b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Three ideal elements of a tragedy include making the audience feel pity and fear, the plot going from good to bad, and the ordinary man, one who is not a villain and one who is not a perfect hero. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'][22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b611a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_dots(input):\n",
    "    # Collapse sequential dots\n",
    "    input = re.sub(\"\\.+\", \".\", input)\n",
    "    # Collapse dots separated by whitespaces\n",
    "    all_collapsed = False\n",
    "    while not all_collapsed:\n",
    "        output = re.sub(r\"\\.(( )*)\\.\", \".\", input)\n",
    "        all_collapsed = input == output\n",
    "        input = output\n",
    "    return output\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def no_punct(string):\n",
    "    string = re.sub(r'[^\\w\\s.!]', '', string)  # delete all punctuation, except for . and !\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68434fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_preprocess(string):\n",
    "    string = \" \".join(tokenize.sent_tokenize(string))\n",
    "    string = re.sub(r'[,:\"]', '', string)\n",
    "    string = string.lower()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a48a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_preprocess(string):\n",
    "    string = light_preprocess(string)\n",
    "    string = remove_stopwords(string)\n",
    "    string = collapse_dots(string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511625a6",
   "metadata": {},
   "source": [
    "As you can see, I used <i><b>sentence tokenization</i> instead of word tokenization, since in this task we should estimate the summary which, mostly, consists of several sentences. I can guess that the word tokenization won't be helpful and can even make some noise.<br><br>\n",
    "I created 2 functions: [light_preprocess] and [hard_preprocess] which I want to use for the next step - modelling.\n",
    "But it's interesting for me to discover how each stage of text manipulation influences the model evaluation. Let's build some model for different columns:\n",
    "- lowercase text, \n",
    "- text without stopwords,\n",
    "- text without stopwords + no punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ffa0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hard_cleaned_text'] = df_train['text'].apply(hard_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9300940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['light_cleaned_text'] = df_train['text'].apply(light_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "015c3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing\n",
    "df_train['low_text'] = df_train['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6234141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "df_train['text_wo_stopwords'] = df_train['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a8cbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all punctuation except for . and !\n",
    "df_train['no_punct_text'] = df_train['text_wo_stopwords'].apply(no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f49c42ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>student_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>hard_cleaned_text</th>\n",
       "      <th>light_cleaned_text</th>\n",
       "      <th>low_text</th>\n",
       "      <th>text_wo_stopwords</th>\n",
       "      <th>no_punct_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff37545b2805</td>\n",
       "      <td>In paragraph two, they would use pickle meat a...</td>\n",
       "      <td>1.520355</td>\n",
       "      <td>-0.292990</td>\n",
       "      <td>paragraph two would use pickle meat would rub ...</td>\n",
       "      <td>in paragraph two they would use pickle meat an...</td>\n",
       "      <td>in paragraph two, they would use pickle meat a...</td>\n",
       "      <td>paragraph two , would use pickle meat would ru...</td>\n",
       "      <td>paragraph two  would use pickle meat would rub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff4ed38ef099</td>\n",
       "      <td>in the first paragraph  it says \"either can it...</td>\n",
       "      <td>-1.204574</td>\n",
       "      <td>-1.169784</td>\n",
       "      <td>first paragraph says either chop sausage also ...</td>\n",
       "      <td>in the first paragraph  it says either can it ...</td>\n",
       "      <td>in the first paragraph  it says \"either can it...</td>\n",
       "      <td>first paragraph says `` either chop sausage ''...</td>\n",
       "      <td>first paragraph says  either chop sausage   al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff53b94f7ce0</td>\n",
       "      <td>They would have piles of filthy meat on the fl...</td>\n",
       "      <td>0.328739</td>\n",
       "      <td>-1.053294</td>\n",
       "      <td>would piles filthy meat floor would get dirty ...</td>\n",
       "      <td>they would have piles of filthy meat on the fl...</td>\n",
       "      <td>they would have piles of filthy meat on the fl...</td>\n",
       "      <td>would piles filthy meat floor would get dirty ...</td>\n",
       "      <td>would piles filthy meat floor would get dirty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>ff7c7e70df07</td>\n",
       "      <td>They used all sorts of chemical concoctions to...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>used sorts chemical concoctions make meat seem...</td>\n",
       "      <td>they used all sorts of chemical concoctions to...</td>\n",
       "      <td>they used all sorts of chemical concoctions to...</td>\n",
       "      <td>used sorts chemical concoctions make meat seem...</td>\n",
       "      <td>used sorts chemical concoctions make meat seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>ebad26</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>fffbccfd8a08</td>\n",
       "      <td>The meat would smell sour but the would \"rub i...</td>\n",
       "      <td>1.771596</td>\n",
       "      <td>0.547742</td>\n",
       "      <td>meat would smell sour would rub soda take away...</td>\n",
       "      <td>the meat would smell sour but the would rub it...</td>\n",
       "      <td>the meat would smell sour but the would \"rub i...</td>\n",
       "      <td>meat would smell sour would `` rub soda take a...</td>\n",
       "      <td>meat would smell sour would  rub soda take awa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prompt_id                                    prompt_question  \\\n",
       "7160    ebad26  Summarize the various ways the factory would u...   \n",
       "7161    ebad26  Summarize the various ways the factory would u...   \n",
       "7162    ebad26  Summarize the various ways the factory would u...   \n",
       "7163    ebad26  Summarize the various ways the factory would u...   \n",
       "7164    ebad26  Summarize the various ways the factory would u...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "7160  Excerpt from The Jungle   \n",
       "7161  Excerpt from The Jungle   \n",
       "7162  Excerpt from The Jungle   \n",
       "7163  Excerpt from The Jungle   \n",
       "7164  Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text    student_id  \\\n",
       "7160  With one member trimming beef in a cannery, an...  ff37545b2805   \n",
       "7161  With one member trimming beef in a cannery, an...  ff4ed38ef099   \n",
       "7162  With one member trimming beef in a cannery, an...  ff53b94f7ce0   \n",
       "7163  With one member trimming beef in a cannery, an...  ff7c7e70df07   \n",
       "7164  With one member trimming beef in a cannery, an...  fffbccfd8a08   \n",
       "\n",
       "                                                   text   content   wording  \\\n",
       "7160  In paragraph two, they would use pickle meat a...  1.520355 -0.292990   \n",
       "7161  in the first paragraph  it says \"either can it... -1.204574 -1.169784   \n",
       "7162  They would have piles of filthy meat on the fl...  0.328739 -1.053294   \n",
       "7163  They used all sorts of chemical concoctions to...  0.205683  0.380538   \n",
       "7164  The meat would smell sour but the would \"rub i...  1.771596  0.547742   \n",
       "\n",
       "                                      hard_cleaned_text  \\\n",
       "7160  paragraph two would use pickle meat would rub ...   \n",
       "7161  first paragraph says either chop sausage also ...   \n",
       "7162  would piles filthy meat floor would get dirty ...   \n",
       "7163  used sorts chemical concoctions make meat seem...   \n",
       "7164  meat would smell sour would rub soda take away...   \n",
       "\n",
       "                                     light_cleaned_text  \\\n",
       "7160  in paragraph two they would use pickle meat an...   \n",
       "7161  in the first paragraph  it says either can it ...   \n",
       "7162  they would have piles of filthy meat on the fl...   \n",
       "7163  they used all sorts of chemical concoctions to...   \n",
       "7164  the meat would smell sour but the would rub it...   \n",
       "\n",
       "                                               low_text  \\\n",
       "7160  in paragraph two, they would use pickle meat a...   \n",
       "7161  in the first paragraph  it says \"either can it...   \n",
       "7162  they would have piles of filthy meat on the fl...   \n",
       "7163  they used all sorts of chemical concoctions to...   \n",
       "7164  the meat would smell sour but the would \"rub i...   \n",
       "\n",
       "                                      text_wo_stopwords  \\\n",
       "7160  paragraph two , would use pickle meat would ru...   \n",
       "7161  first paragraph says `` either chop sausage ''...   \n",
       "7162  would piles filthy meat floor would get dirty ...   \n",
       "7163  used sorts chemical concoctions make meat seem...   \n",
       "7164  meat would smell sour would `` rub soda take a...   \n",
       "\n",
       "                                          no_punct_text  \n",
       "7160  paragraph two  would use pickle meat would rub...  \n",
       "7161  first paragraph says  either chop sausage   al...  \n",
       "7162  would piles filthy meat floor would get dirty ...  \n",
       "7163  used sorts chemical concoctions make meat seem...  \n",
       "7164  meat would smell sour would  rub soda take awa...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a2c94",
   "metadata": {},
   "source": [
    "I'm also kind of curious how stemming will impact the model implementing. I guess, that it will make the data work worse. Let's see it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9368b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "df_train['stemmed_text'] = df_train['text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03f4fb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one element of a perfect trageri in aristotl 's opinion is a plot that is arrang `` ... not on the simpl but on the complex ... '' in other word , aristotl believ good trageri have complex plotlin . he also think they need to have action that `` ... excit piti and fear ... the distinct mark of tragin imit . '' aristotl believ good trageri incit neg emot which caus the event of the plot . final , aristitl believ the perfect tragedi should have a downfal caus by `` ... some error of judgement or frailiti . '' the charact should not be neither good nor evil , and should sompli have made a mistak .\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['stemmed_text'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c5183",
   "metadata": {},
   "source": [
    "### Step four - modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b907bf",
   "metadata": {},
   "source": [
    "OK, let's see how the ML model will work on differently manipulated text data.\n",
    "I will use <b>SVR</b> model.<br>\n",
    "The function 'svr_pipeline' builds a SVR model with given vectorization type, text data and target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1555b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_pipeline(model, vectorizer, column_name, target):\n",
    "    X = df_train[column_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.25, random_state=42)\n",
    "    print(\"Building SVR model using \" + \"[\" + column_name + \"] column\")\n",
    "    pipe_svr = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('regressor', model)])\n",
    "    pipe_svr.fit(X_train, y_train)\n",
    "    y_train_pred = pipe_svr.predict(X_train)\n",
    "    y_test_pred = pipe_svr.predict(X_test)\n",
    "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "    print(f\"MSE for train data: {mse_train}\")\n",
    "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "    print(f\"MSE for test data: {mse_test}\")\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05a278d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', lowercase=True)\n",
    "tfidf = TfidfVectorizer(analyzer='word', lowercase=True)\n",
    "svr = SVR(C=1.0)\n",
    "y_content = df_train['content']\n",
    "y_word = df_train['wording']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7a77931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************RESULTS FOR THE FIRST TARGET: CONTENT****************************\n",
      "\n",
      "\n",
      "Building SVR model using [low_text] column\n",
      "MSE for train data: 0.08966398475888973\n",
      "MSE for test data: 0.21669235218348495\n",
      "---------------------------------\n",
      "Building SVR model using [text_wo_stopwords] column\n",
      "MSE for train data: 0.056917403043997714\n",
      "MSE for test data: 0.24875573479145577\n",
      "---------------------------------\n",
      "Building SVR model using [no_punct_text] column\n",
      "MSE for train data: 0.056571025592482484\n",
      "MSE for test data: 0.2490175289194579\n",
      "---------------------------------\n",
      "Building SVR model using [light_cleaned_text] column\n",
      "MSE for train data: 0.08969421941061177\n",
      "MSE for test data: 0.2174345984025782\n",
      "---------------------------------\n",
      "Building SVR model using [hard_cleaned_text] column\n",
      "MSE for train data: 0.05673314927548134\n",
      "MSE for test data: 0.24903090048222726\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "columns = ['low_text', 'text_wo_stopwords', 'no_punct_text', 'light_cleaned_text', 'hard_cleaned_text']\n",
    "print(\"****************************RESULTS FOR THE FIRST TARGET: CONTENT****************************\\n\\n\")\n",
    "for column in columns:\n",
    "    svr_pipeline(svr, cv, column, y_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d843b96b",
   "metadata": {},
   "source": [
    "We have worked with the first target - <b>content scoring</b>. Some conclusions about it:\n",
    "- light preprocessing gives the best performance out of all.\n",
    "- surpisingly, but we can also see that removing stopwords didn't help at all: it gave a little worse results for test data\n",
    "- removing punctuation wasn't helpful too. <br>\n",
    "\n",
    "As a result, it's OK to use only lowercasing or light preprocessing technique for this target.\n",
    "But as we see, it seems to have an overfitting problem. In the next steps I will try Grid Search for searching the best parameters.<br>\n",
    "\n",
    "Now let's see the results for the second target - <b>wording</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f670189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************RESULTS FOR THE SECOND TARGET: WORDING****************************\n",
      "\n",
      "\n",
      "Building SVR model using [low_text] column\n",
      "MSE for train data: 0.20557759921496446\n",
      "MSE for test data: 0.41682474759156435\n",
      "---------------------------------\n",
      "Building SVR model using [text_wo_stopwords] column\n",
      "MSE for train data: 0.13314402703367734\n",
      "MSE for test data: 0.4363685734869618\n",
      "---------------------------------\n",
      "Building SVR model using [no_punct_text] column\n",
      "MSE for train data: 0.13268255975464247\n",
      "MSE for test data: 0.43450798125714246\n",
      "---------------------------------\n",
      "Building SVR model using [light_cleaned_text] column\n",
      "MSE for train data: 0.20565061990716488\n",
      "MSE for test data: 0.4162586192369878\n",
      "---------------------------------\n",
      "Building SVR model using [hard_cleaned_text] column\n",
      "MSE for train data: 0.13304255673812543\n",
      "MSE for test data: 0.4354985823137249\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"****************************RESULTS FOR THE SECOND TARGET: WORDING****************************\\n\\n\")\n",
    "for column in columns:\n",
    "    svr_pipeline(svr, cv, column, y_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f31da",
   "metadata": {},
   "source": [
    "As I considered earlier, removing punctuation wasn't really helpful: instead, it made worse overfitting.\n",
    "In this scenario we can also see that light preprocessing gives better performance for the second model too.<br>\n",
    "<u><b>Conclusion</b></u>: we shouldn't use hard preprocessing methods for this business task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a5c56",
   "metadata": {},
   "source": [
    "Let's calculate the main metric - MCRMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea7118ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(model, vectorizer, column_name, target):\n",
    "    X = df_train[column_name]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.25, random_state=42)\n",
    "    svr = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('regressor', model)])\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b83e17a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_c = get_rmse(svr, cv, 'light_cleaned_text', y_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a311e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_w = get_rmse(svr, cv, 'light_cleaned_text', y_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd591c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.5557399521383988\n"
     ]
    }
   ],
   "source": [
    "mcrmse = np.mean([rmse_c, rmse_w])\n",
    "print(\"MCRMSE:\", mcrmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c96fe0",
   "metadata": {},
   "source": [
    "###### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e5771",
   "metadata": {},
   "source": [
    "Now, let's try another type of vectorization for this pipeline: <u>TF-IDF</u> vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e380a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************RESULTS FOR THE FIRST TARGET: CONTENT****************************\n",
      "\n",
      "\n",
      "Building SVR model using [low_text] column\n",
      "MSE for train data: 0.05916774003585051\n",
      "MSE for test data: 0.3238264762198225\n",
      "---------------------------------\n",
      "Building SVR model using [text_wo_stopwords] column\n",
      "MSE for train data: 0.07510784445053639\n",
      "MSE for test data: 0.4017979504332975\n",
      "---------------------------------\n",
      "Building SVR model using [no_punct_text] column\n",
      "MSE for train data: 0.07401829067332151\n",
      "MSE for test data: 0.4028591661611453\n",
      "---------------------------------\n",
      "Building SVR model using [light_cleaned_text] column\n",
      "MSE for train data: 0.059096388156599934\n",
      "MSE for test data: 0.32594658603508037\n",
      "---------------------------------\n",
      "Building SVR model using [hard_cleaned_text] column\n",
      "MSE for train data: 0.0747551342913757\n",
      "MSE for test data: 0.4037568257246403\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"****************************RESULTS FOR THE FIRST TARGET: CONTENT****************************\\n\\n\")\n",
    "for column in columns:\n",
    "    svr_pipeline(svr, tfidf, column, y_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "674c7603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************RESULTS FOR THE SECOND TARGET: WORDING****************************\n",
      "\n",
      "\n",
      "Building SVR model using [low_text] column\n",
      "MSE for train data: 0.1065637587455695\n",
      "MSE for test data: 0.49993695442349173\n",
      "---------------------------------\n",
      "Building SVR model using [text_wo_stopwords] column\n",
      "MSE for train data: 0.11708665265505039\n",
      "MSE for test data: 0.5702556674801257\n",
      "---------------------------------\n",
      "Building SVR model using [no_punct_text] column\n",
      "MSE for train data: 0.11599825790744665\n",
      "MSE for test data: 0.5707846355551858\n",
      "---------------------------------\n",
      "Building SVR model using [light_cleaned_text] column\n",
      "MSE for train data: 0.10613813135470206\n",
      "MSE for test data: 0.5004364817706187\n",
      "---------------------------------\n",
      "Building SVR model using [hard_cleaned_text] column\n",
      "MSE for train data: 0.11647335826522358\n",
      "MSE for test data: 0.5700677154660999\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"****************************RESULTS FOR THE SECOND TARGET: WORDING****************************\\n\\n\")\n",
    "for column in columns:\n",
    "    svr_pipeline(svr, tfidf, column, y_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e90d81",
   "metadata": {},
   "source": [
    "Using this type of vectorization have us a bit worse results. But the same situation occurs: light preprocessing is more valuable in this case than hard one. <br>\n",
    "Conclusion: for the next steps I will use <b>[light_cleaned_text]</b> column for both target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba6f9bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.639166336433563\n"
     ]
    }
   ],
   "source": [
    "# let's calculate the key metric\n",
    "rmse_c2 = get_rmse(svr, tfidf, 'light_cleaned_text', y_content)\n",
    "rmse_w2 = get_rmse(svr, tfidf, 'light_cleaned_text', y_word)\n",
    "mcrmse_2 = np.mean([rmse_c2, rmse_w2])\n",
    "print(\"MCRMSE:\", mcrmse_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25852989",
   "metadata": {},
   "source": [
    "In the next steps I will use Bag of Words vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065739e",
   "metadata": {},
   "source": [
    "### Step five - Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8cff22",
   "metadata": {},
   "source": [
    "##### Grid Search for the first target - content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21ca2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'regressor__C' : [0.5, 1, 5, 10],\n",
    "         'regressor__epsilon': [0.001, 0.01, 0.05, 0.1, 0.5, 1]}\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(df_train['light_cleaned_text'], y_content, \n",
    "                                                     test_size=0.25, random_state=42)\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(df_train['light_cleaned_text'], y_word, \n",
    "                                                     test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "00d2fd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters are:  {'regressor__C': 1, 'regressor__epsilon': 0.1}\n"
     ]
    }
   ],
   "source": [
    "pipe_svr = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(\n",
    "            analyzer='word',\n",
    "            lowercase=True\n",
    "        )),\n",
    "        ('regressor', SVR(C=1.0))\n",
    "    ])\n",
    "\n",
    "grid_c = GridSearchCV(estimator=pipe_svr, param_grid=params,\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_c.fit(Xc_train, yc_train)\n",
    "print(\"Best parameters are: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810ee81",
   "metadata": {},
   "source": [
    "##### Grid Search for the second target - wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a47f4ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters are:  {'regressor__C': 5, 'regressor__epsilon': 0.5}\n"
     ]
    }
   ],
   "source": [
    "grid_w = GridSearchCV(estimator=pipe_svr, param_grid=params,\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_w.fit(Xw_train, yw_train)\n",
    "print(\"Best parameters are: \", grid_w.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3d504ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.42060775728842353\n"
     ]
    }
   ],
   "source": [
    "best_model_w = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(\n",
    "            analyzer='word',\n",
    "            lowercase=True\n",
    "        )),\n",
    "        ('regressor', SVR(C=5, epsilon = 0.5))\n",
    "    ])\n",
    "best_model_w.fit(Xw_train, yw_train)\n",
    "best_mse_w = mean_squared_error(yw_test, best_model_w.predict(Xw_test))\n",
    "print(\"MSE:\", best_mse_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc833f2",
   "metadata": {},
   "source": [
    "### Step six - using other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60dfcc1",
   "metadata": {},
   "source": [
    "###### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9384348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for train data: 0.035187343263108864\n",
      "MSE for test data: 0.48466938011214605\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "X = df_train['light_cleaned_text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_content, test_size=0.25, random_state=42)\n",
    "pipe_ridge = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(\n",
    "        analyzer='word',\n",
    "        lowercase=True\n",
    "    )),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "pipe_ridge.fit(X_train, y_train)\n",
    "mse_train_ridge = mean_squared_error(y_train, pipe_ridge.predict(X_train))\n",
    "print(f\"MSE for train data: {mse_train_ridge}\")\n",
    "mse_test_ridge = mean_squared_error(y_test, pipe_ridge.predict(X_test))\n",
    "print(f\"MSE for test data: {mse_test_ridge}\")\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aca7be2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE: 0.7696402423573192\n"
     ]
    }
   ],
   "source": [
    "rmse_c_ridge = get_rmse(Ridge(), cv, 'light_cleaned_text', y_content)\n",
    "rmse_w_ridge = get_rmse(Ridge(), cv, 'light_cleaned_text', y_word)\n",
    "mcrmse_ridge = np.mean([rmse_c_ridge, rmse_w_ridge])\n",
    "print(\"MCRMSE:\", mcrmse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fded9",
   "metadata": {},
   "source": [
    "###### Grid Search for Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b321edf",
   "metadata": {},
   "source": [
    "###### First target - Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dabcfc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "Best Parameters:  {'regressor__alpha': 10, 'regressor__solver': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'regressor__alpha': [0.1, 1, 10],\n",
    "              'regressor__solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']}\n",
    "\n",
    "grid_ridge_c = GridSearchCV(pipe_ridge, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_ridge_c.fit(Xc_train, yc_train)\n",
    "print(\"Best Parameters: \", grid_ridge_c.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84a251",
   "metadata": {},
   "source": [
    "##### Second target - Wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9351c65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n",
      "Best Parameters:  {'regressor__alpha': 10, 'regressor__solver': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "grid_ridge_w = GridSearchCV(pipe_ridge, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "grid_ridge_w.fit(Xw_train, yw_train)\n",
    "print(\"Best Parameters: \", grid_ridge_w.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7aaac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3524896062257789\n"
     ]
    }
   ],
   "source": [
    "best_ridge = grid_search.best_estimator_\n",
    "best_ridge.fit(X_train, y_train)\n",
    "best_mse_ridge = mean_squared_error(y_test, best_ridge.predict(X_test))\n",
    "print(\"MSE:\", best_mse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723d63e",
   "metadata": {},
   "source": [
    "### Step seven - choosing best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9287aac",
   "metadata": {},
   "source": [
    "Firstly, let's look at how each model works for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc679c9",
   "metadata": {},
   "source": [
    "##### SVR - Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e403ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr_c = grid_c.best_estimator_\n",
    "best_svr_c.fit(Xc_train, yc_train)\n",
    "mse_1 = mean_squared_error(yc_test, best_svr_c.predict(Xc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041da72f",
   "metadata": {},
   "source": [
    "##### SVR - Wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d88b21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svr_w = grid_w.best_estimator_\n",
    "best_svr_w.fit(Xw_train, yw_train)\n",
    "mse_2 = mean_squared_error(yw_test, best_svr_w.predict(Xw_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39b70294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE of the best model: 0.5574208123869361\n"
     ]
    }
   ],
   "source": [
    "# calculating the key metric\n",
    "rmse_1 = np.sqrt(mse_1)\n",
    "rmse_2 = np.sqrt(mse_2)\n",
    "mcrmse = np.mean([rmse_1, rmse_2])\n",
    "print(\"MCRMSE of the best model:\", mcrmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23c701",
   "metadata": {},
   "source": [
    "##### Ridge Regression - Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "754b13c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3524896062257789\n"
     ]
    }
   ],
   "source": [
    "best_ridge_c = grid_ridge_c.best_estimator_\n",
    "best_ridge_c.fit(Xc_train, yc_train)\n",
    "mse_ridge_1 = mean_squared_error(yc_test, best_ridge_c.predict(Xc_test))\n",
    "print(\"MSE:\", mse_ridge_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d9ad9",
   "metadata": {},
   "source": [
    "##### Ridge Regression - Wording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcba1d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5381537228871931\n"
     ]
    }
   ],
   "source": [
    "best_ridge_w = grid_ridge_w.best_estimator_\n",
    "best_ridge_w.fit(Xw_train, yw_train)\n",
    "mse_ridge_2 = mean_squared_error(yw_test, best_ridge_w.predict(Xw_test))\n",
    "print(\"MSE:\", mse_ridge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec3ca4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCRMSE of the best model: 0.6636489829564038\n"
     ]
    }
   ],
   "source": [
    "# calculating the key metric\n",
    "rmse_ridge_1 = np.sqrt(mse_ridge_1)\n",
    "rmse_ridge_2 = np.sqrt(mse_ridge_2)\n",
    "mcrmse_ridge = np.mean([rmse_ridge_1, rmse_ridge_2])\n",
    "print(\"MCRMSE of the best model:\", mcrmse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548f331",
   "metadata": {},
   "source": [
    "Judging from the MCRMSE values, SVR advanced models work better for this data than Ridge Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028de14",
   "metadata": {},
   "source": [
    "### Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5dc583",
   "metadata": {},
   "source": [
    "During this work:\n",
    "- There were used different types of text preprocessing methods, such as lowercasing, tokenization, removing stopwords etc. I also compared how each of them influences the model performance. Conclusion of this part: light text preprocessing works better than hard(within removing stopwords).\n",
    "- There were used 2 types of ML models: SVR and Ridge Regression.\n",
    "- There were used 2 types of vectorization: BoW and TF-IDF. \n",
    "- There was implemented GridSearchCV for both models in order to find the best values for hyperparameters.\n",
    "- There was chosen the best model - SVR with hyperparameters C=1.0 and epsilon = 0.1 for the first target; C=5, epsilon = 0.5 for the second target.\n",
    "- There were several calculation of the key metric MCRMSE. The best model gave result that MCRMSE = 0.557.\n",
    "\n",
    "Some further possible improvements in order to discover the model performance and make it better:\n",
    "- using cross validation;\n",
    "- using sentence embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23510615",
   "metadata": {},
   "source": [
    "### P.S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1388a4",
   "metadata": {},
   "source": [
    "I forgot to see how stemming impacts the model performance. Let's find out it quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "884669a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for the first target - content:\n",
      "Building SVR model using [stemmed_text] column\n",
      "MSE for train data: 0.09240368229610203\n",
      "MSE for test data: 0.21369541196528147\n",
      "---------------------------------\n",
      "Result for the second target - wording:\n",
      "Building SVR model using [stemmed_text] column\n",
      "MSE for train data: 0.2096695269040362\n",
      "MSE for test data: 0.4162108707676716\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Result for the first target - content:\")\n",
    "svr_pipeline(svr, cv, 'stemmed_text', y_content)\n",
    "print(\"Result for the second target - wording:\")\n",
    "svr_pipeline(svr, cv, 'stemmed_text', y_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0828f72",
   "metadata": {},
   "source": [
    "Looks interesting. The results of MSE values are simillar to that ones where I used light_preprocessing. It seems that I could also use this technique for the further steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
